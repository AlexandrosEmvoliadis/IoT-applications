# -*- coding: utf-8 -*-
# data_augmentation.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1cPx3-cGyZxal2QAgmPxTHDg7vJdeaQGO



# DATA AUGMENTATION,OUR DATASET HAS JUST 14 SAMPLES(7 FOR EACH CLASS). GOOD THING THA MOST FEATURES DOES NOT SHARE A SAME DISTRIBUTION AMONG CLASSES


#!pip install sdv --> this should be installed
from sdv.metadata import SingleTableMetadata
from sdv.single_table import CTGANSynthesizer,CopulaGANSynthesizer
from scipy.signal import welch,lfilter,butter
from sklearn.preprocessing import StandardScaler
import numpy as np
import os
import pandas as pd
import random
import numpy as np

import warnings
warnings.filterwarnings("ignore")


path_to_data = './dataframes'
Unique_Data_Frames = os.listdir(path_to_data)

path_to_data_ = './dataframes_expanded'
Unique_Data_Frames_ = os.listdir(path_to_data_)

def find_outliers_IQR(df):
   q1=df.quantile(0.25)
   q3=df.quantile(0.75)
   IQR=q3-q1
   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]
   return outliers

def replace_outliers_(feature):
  q1=feature.quantile(0.25)
  q3=feature.quantile(0.75)
  m = feature.mean()
  s = feature.std()
  iqr = q3-q1
  for idx in range(feature.shape[0]):
    if feature[idx] > q3+1.5*iqr:
      feature[idx] = random.uniform(q3,q3+1.5*iqr)
    if feature[idx] < q1-1.5*iqr:
      feature[idx] = random.uniform(q1-1.5*iqr,q1)
  return feature

for file in Unique_Data_Frames:
  if file == 'Healthy.csv':
    df_normal = pd.read_csv(path_to_data + '/' + file)
  if file == 'Parcinson.csv':
    df_pd = pd.read_csv(path_to_data + '/' + file)
  if file == 'Total.csv':
    df_total = pd.read_csv(path_to_data + '/' + file)

for file in Unique_Data_Frames_:
  if file == 'Healthy.csv':
    df_normal_ = pd.read_csv(path_to_data_ + '/' + file)
  if file == 'Parcinson.csv':
    df_pd_ = pd.read_csv(path_to_data_ + '/' + file)
  if file == 'Total.csv':
    df_total_ = pd.read_csv(path_to_data_ + '/' + file)

df_normal = df_normal.T[1:]
df_normal = df_normal.T

df_pd = df_pd.T[1:]
df_pd = df_pd.T

df_normal_ = df_normal_.T[1:]
df_normal_ = df_normal_.T

df_pd_ = df_pd_.T[1:]
df_pd_ = df_pd_.T

print(df_pd.shape)
print(df_normal.shape)

for col in df_normal.columns:
  df_normal[col] = replace_outliers_(df_normal[col])

for col in df_pd.columns:
  df_pd[col] = replace_outliers_(df_pd[col])

print(find_outliers_IQR(df_normal))
print(find_outliers_IQR(df_pd))

print(df_normal)
print(df_pd)

if not os.path.exists('./modified_outliers'):
  os.mkdir('./modified_outliers')
df_normal.to_csv('./modified_outliers/' + 'Healthy.csv')
df_pd.to_csv('./modified_outliers/' + 'Parcinson.csv')

healthy = df_normal.to_numpy()
parc = df_pd.to_numpy()

healthy_ = df_normal_.to_numpy()
parc_ = df_pd_.to_numpy()

print(healthy.shape)
print(parc_.shape)

fake_healthy = np.zeros((3,39))
fake_parc = np.zeros((3,39))
for jdx in range (3):
  for idx in range (39):
    fake_healthy[jdx][idx] = healthy[random.randint(0,6)][idx]
    fake_parc[jdx][idx] = parc[random.randint(0,6)][idx]

n_parc = np.concatenate((parc,fake_parc))
df_parc = pd.DataFrame(n_parc,columns = df_pd.columns.values)
n_healthy = np.concatenate((healthy,fake_healthy))
df_healthy = pd.DataFrame(n_healthy,columns = df_pd.columns.values)

#New Version: Generate MetaData


# This is the default folder name that the GOogle Colab notebook uses.
# Change this if you have your own folder with CSV files.
FOLDER_NAME = './modified_outliers'
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(data=df_healthy)
# Print metadata
#ASKED FEATURES DATA AUGMENTATION
model_1 = CTGANSynthesizer(metadata = metadata)
model_2 = CopulaGANSynthesizer(metadata = metadata)
model_1.fit(df_healthy)
model_2.fit(df_healthy)

new_healthy_ctgan = model_1.sample(100)
new_healthy_copulagan = model_2.sample(100)
print("Generated Finsihed:100")
new_healthy_ctgan_ = model_1.sample(1000)
new_healthy_copulagan_ = model_2.sample(1000)
print("Generated Finsihed:1000")

new_healthy_ctgan__ = model_1.sample(10000)
new_healthy_copulagan__ = model_2.sample(10000)
print("Generated Finsihed:10000")

print(df_healthy.shape)
model_1.fit(df_parc)
model_2.fit(df_parc)

new_parc_ctgan = model_1.sample(100)
new_parc_copulagan = model_2.sample(100)
print("Generated Finsihed:100")

new_parc_ctgan_ = model_1.sample(1000)
new_parc_copulagan_ = model_2.sample(1000)
print("Generated Finsihed:1000")

new_parc_ctgan__ = model_1.sample(10000)
new_parc_copulagan__ = model_2.sample(10000)
print("Generated Finsihed:10000")

print(parc_.shape)
fake_healthy = np.zeros((3,51))
fake_parc = np.zeros((3,51))
for jdx in range (3):
  for idx in range (51):
    fake_healthy[jdx][idx] = healthy_[random.randint(0,6)][idx]
    fake_parc[jdx][idx] = parc_[random.randint(0,6)][idx]

n_parc = np.concatenate((parc_,fake_parc))
df_parc_ = pd.DataFrame(n_parc,columns = df_pd_.columns.values)
n_healthy = np.concatenate((healthy_,fake_healthy))
df_healthy_ = pd.DataFrame(n_healthy,columns = df_pd_.columns.values)

#EXPANDED FEATURES,DATA AUGMENTATION

metadata = SingleTableMetadata()
metadata.detect_from_dataframe(data=df_healthy_)

model_1 = CTGANSynthesizer(metadata = metadata)
model_2 = CopulaGANSynthesizer(metadata = metadata)
print(df_healthy_.shape)
model_1.fit(df_healthy_)
model_2.fit(df_healthy_)

new_healthy_ctgan_exp = model_1.sample(100)
new_healthy_copulagan_exp = model_2.sample(100)
print("Generated Finsihed:100")

new_healthy_ctgan_exp_ = model_1.sample(1000)
new_healthy_copulagan_exp_ = model_2.sample(1000)
print("Generated Finsihed:1000")

new_healthy_ctgan_exp__ = model_1.sample(10000)
new_healthy_copulagan_exp__ = model_2.sample(10000)
print("Generated Finsihed:10000")

print(df_healthy.shape)
model_1.fit(df_parc_)
model_2.fit(df_parc_)

new_parc_ctgan_exp = model_1.sample(100)
new_parc_copulagan_exp = model_2.sample(100)
print("Generated Finsihed:100")

new_parc_ctgan_exp_ = model_1.sample(1000)
new_parc_copulagan_exp_ = model_2.sample(1000)
print("Generated Finsihed:1000")

new_parc_ctgan_exp__ = model_1.sample(10000)
new_parc_copulagan_exp__ = model_2.sample(10000)
print("Generated Finsihed:10000")

if not os.path.exists('./ctgan_custom'):
  os.mkdir('./ctgan_custom')
if not os.path.exists('./cgan_custom'):
  os.mkdir('./cgan_custom')

if not os.path.exists('./ctgan_expanded'):
  os.mkdir('./ctgan_expanded')
if not os.path.exists('./cgan_expanded'):
  os.mkdir('./cgan_expanded')


new_healthy_ctgan.to_csv('./ctgan_custom/' + 'Healthy_100.csv')
new_healthy_ctgan_.to_csv('./ctgan_custom/' + 'Healthy_1000.csv')
new_healthy_ctgan__.to_csv('./ctgan_custom/' + 'Healthy_10000.csv')

new_healthy_copulagan.to_csv('./cgan_custom/' + 'Healthy_100.csv')
new_healthy_copulagan_.to_csv('./cgan_custom/' + 'Healthy_1000.csv')
new_healthy_copulagan__.to_csv('./cgan_custom/' + 'Healthy_10000.csv')

new_parc_ctgan.to_csv('./ctgan_custom/' + 'Parcinson_100.csv')
new_parc_ctgan_.to_csv('./ctgan_custom/' + 'Parcinson_1000.csv')
new_parc_ctgan__.to_csv('./ctgan_custom/' + 'Parcinson_10000.csv')

new_parc_copulagan.to_csv('./cgan_custom/' + 'Parcinson_100.csv')
new_parc_copulagan_.to_csv('./cgan_custom/' + 'Parcinson_1000.csv')
new_parc_copulagan__.to_csv('./cgan_custom/' + 'Parcinson_10000.csv')


new_healthy_ctgan_exp.to_csv('./ctgan_expanded/' + 'Healthy_100.csv')
new_healthy_ctgan_exp_.to_csv('./ctgan_expanded/' + 'Healthy_1000.csv')
new_healthy_ctgan_exp__.to_csv('./ctgan_expanded/' + 'Healthy_10000.csv')


new_healthy_copulagan_exp.to_csv('./cgan_expanded/' + 'Healthy_100.csv')
new_healthy_copulagan_exp_.to_csv('./cgan_expanded/' + 'Healthy_1000.csv')
new_healthy_copulagan_exp__.to_csv('./cgan_expanded/' + 'Healthy_10000.csv')

new_parc_ctgan_exp.to_csv('./ctgan_expanded/' + 'Parcinson_100.csv')
new_parc_ctgan_exp_.to_csv('./ctgan_expanded/' + 'Parcinson_1000.csv')
new_parc_ctgan_exp__.to_csv('./ctgan_expanded/' + 'Parcinson_10000.csv')

new_parc_copulagan_exp.to_csv('./cgan_expanded/' + 'Parcinson_100.csv')
new_parc_copulagan_exp_.to_csv('./cgan_expanded/' + 'Parcinson_1000.csv')
new_parc_copulagan_exp__.to_csv('./cgan_expanded/' + 'Parcinson_10000.csv')