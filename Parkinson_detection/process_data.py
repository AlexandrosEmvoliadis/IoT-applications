# -*- coding: utf-8 -*-
# process_data.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1GNdx7ktpmKubQqf1fpUgFSFl5mW7QM0h




# IMPORT LIBRARIES


from scipy.signal import welch,lfilter,butter
from sklearn.preprocessing import StandardScaler
import numpy as np
import os
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import mannwhitneyu,ranksums
from math import sqrt
import os

import warnings
warnings.filterwarnings("ignore")

# PREPROCESSING FUNCTIONS

#butterworth filter
def butter_bandpass(lowcut, highcut, fs, order):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a


def butter_bandpass_filter(data, lowcut, highcut, fs, order):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)
    return y

#standard Scaler mean = 0 std_var = 1
def scaling(data):
    scal = StandardScaler(with_mean = 0,with_std=1)
    n_data = scal.fit_transform(data)
    return n_data

#downsampling to 2Hz
def downsampling(data):
    downsampled_data = data[0::500]
    return downsampled_data

#set range between -1 and 1 for inpu_min = 0 and input_max = 65535
def set_range(data,x_min,x_max):
    new_data = np.zeros(data.shape[0])
    for idx in range(data.shape[0]):
        new_data[idx] = 2*(data[idx]-x_min)/(x_max)-1
    return new_data


# SET DIRECTORIES



path_to_data = './EGG_data/EGG_data'
Unique_Labels_List = os.listdir(path_to_data)



# THIS CELL IS FOR EXAMINING BEST FIT FOR BUTTERWORTH FILTER

fin = list()
for file in Unique_Labels_List:
  df = pd.read_csv(path_to_data + '/' + file)
  data = np.asarray(df)
  data = set_range(data,0,65535)
  data = scaling(data.reshape(-1,1))
  data = downsampling(data)
  low = 0.0065
  high = 0.25
  data = butter_bandpass_filter(data,low,high,1,4)
  fin.append(data)
print("Finished with Butterworth")
x = np.asarray(fin)
x.reshape(28,3600)
plt.plot(x[0])
plt.show()

# PLOT BUTTERWORTH OUTPUT, ORDER 4 SUPPRESSES HARMONICS,SINCE THIS ORDER IS SELECTED

for i in range(3):
  plt.plot(fin[i])
  plt.show()

#from the plots above, it is clear that the greater the order of butterworth filter, the lower the magnitude of oura data. We choose order 4 for this reason
data = np.asarray(fin)


# GET LISTS FOR TASKS 1,2,5,6(MEAN DOMINANT POWER/FREQUENCY, TOTAL DOMINANT POWER/FREQUENCY,NGSW,PEPD
# *(STD DEVIATION FOR 1 IS COMPUTED ON THE NEXT CELL)



# task 5, preprocess

normal_gastric_percentage = []

# task 6, preprocess

pped_dist = []

# task 1, preprocess (except from std deviation)

mean_dom_power_window = []
mean_dom_freq_window = []

# task 2, preprocess

max_power_total = []
max_freq_total = []
for file in Unique_Labels_List:
      zone_1 = []
      zone_2 = []
      zone_3 = []
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      counter = 0
      max_pow = 0
      max_freq= 0
      counter = 0
      normal_gastric_freq = 0
      tot_power = 0
      #custom overlaping windows
      for idx in range(27):
          
          counter+=1
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power(and sum all max powers)
          max_pow+= np.amax(power)
          #get idx of max power
          max_idx = (np.where(power == np.amax(power)))
         
          #get max frequency(and sum all max frequencies)
          max_freq+=freq[max_idx[1]]
          #get noraml gastric fasi (task 5)
          if freq[max_idx[1]]>=0.033 and freq[max_idx[1]]<=0.067:
              normal_gastric_freq+=1
          #plot for visually checking purposes
          '''
          plt.semilogy(freq,power.T)
          plt.title(file + "Window: " + str(i+1))
          plt.xlabel("Frequency (Hz)")
          plt.ylabel("Spectral Power (dB)")
          plt.xlim(0,0.168)
          plt.show()
          '''
      mean_dom_power_window.append(max_pow/27)
      mean_dom_freq_window.append(max_freq/27)
      normal_gastric_percentage.append(normal_gastric_freq/27)
      #print(max_pow/counter)
      #print(max_freq/counter)
      freq_,power_ = welch(data.T,noverlap = 0,fs = 2)
      #print(power_.shape)
      max_power_total.append(np.amax(power_))
      max_idx_ = (np.where(power_ == np.amax(power_)))
      max_freq_total.append(freq_[max_idx_[1]])
      for f in freq_:
        if f <0.033:
          zone_1.append(np.where(freq==f))
        if f >=0.033 and f<=0.0667:
          zone_2.append(np.where(freq==f))
        if f <=0.167 and f>0.067:
          zone_3.append(np.where(freq==f))   
      #compute PPED, taking as total power sum of powers in [0,0.167]Hz 
      tot_power = np.sum(power_.T)
      power1 = np.sum(power_.T[0:5])
      power2 = np.sum(power_.T[5:9])
      power3 = np.sum(power_.T[9:21])
      pped_dist.append([power1/tot_power,power2/tot_power,power3/tot_power])
      #print(freq_.shape)
      '''
      sum_tot_pow = np.sum(power_)
      plt.semilogy(freq_,power_.reshape(-1))
      plt.title(file + 'whole_signal')
      plt.xlabel("Frequency Hz")
      plt.ylabel('Spectrum')
      plt.show()

print(normal_gastric_percentage)  
print(max_power_total)
print(max_freq_total) 
print(zone_1,zone_2,zone_3)
'''

# HERE WE COMPUTE STD DEVIATION FOR POWER AND FREQUENCY FOR WINDOWS(TASK 1)

std_dev_pow = []
std_dev_freq = []
counter_file = 0
for file in Unique_Labels_List:
      
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      #sums for stds
      sum_pow = 0
      sum_freq = 0
      #custom overlaping windows
      for idx in range(27):
          max_pow = 0
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power(and sum all max powers)
          max_pow= np.amax(power)
          #get idx of max power
          max_idx = (np.where(power == np.amax(power)))
          #create sum in order to compute standard deviation for power
          sum_pow += (max_pow - mean_dom_power_window[counter_file])**2 
          #get max frequency(and sum all max frequencies)
          max_freq=freq[max_idx[1]]
          #create sum in order to compute standard deviation for power
          sum_freq +=(max_freq - mean_dom_freq_window[counter_file])**2
      #append values in lists 
      std_pow = sqrt(sum_pow/26)
      std_freq = sqrt(sum_freq/26)
      std_dev_pow.append(std_pow)
      std_dev_freq.append(std_freq)
         
      counter_file+=1

# GET DPR(TASK 3)

DPR = []
for idx in range(int(len(mean_dom_power_window)/2)):
  #computed from formula
  DPR.append(mean_dom_power_window[2*idx]/mean_dom_power_window[2*idx+1])

# GET PIC AND FIC(TASK 4)

PIC = []
FIC = []
for idx in range(len(mean_dom_power_window)):
  #computed from formula
  PIC.append(std_dev_pow[idx]/mean_dom_power_window[idx])
  FIC.append(std_dev_freq[idx]/mean_dom_freq_window[idx])

# COMPUTATION OF MEAN/STD DEV PPED FOR WINDOWS FOR EACH FILE
# GET INSIDE EACH WINDOW, GET PPED FOR EACH WINDOW, SUM EVERYTHING AND DIVIDE BY THE NUMBER OF WINDOWS(MEAN)
# AGAIN,GET IN EACH WINDOW FOR EACH FILE,AND ADD (PPED[WIN_IDX]-PPED[MEAN])^2
# THEN DIVIDE BY THE SUM OF WINDOWS SUBSTRACTED BY 1(TASK 7)


mean_pped = []

for file in Unique_Labels_List:
      
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      #sums for means
      sum_power_1 = 0
      sum_power_2 = 0
      sum_power_3 = 0
      #custom overlaping windows
      for idx in range(27):
          max_pow = 0
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power(and sum all max powers for mean pped)
          tot_pow = np.sum(power.T)
          power_1 = np.sum(power.T[0:5])
          power_2 = np.sum(power.T[5:9])
          power_3 = np.sum(power.T[9:21])
          sum_power_1+=power_1/tot_pow
          sum_power_2+=power_2/tot_pow
          sum_power_3+=power_3/sum_pow
      #append values in lists 
      mean_pped.append([sum_power_1/27,sum_power_2/27,sum_power_3/27])
         
      counter_file+=1

#COMPUTE STD DEVIATION FOR PPED(TASK 7)

std_dev_pped = []
counter_file = 0
for file in Unique_Labels_List:
      
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      #sums for stds
      sum_power_1 = 0
      sum_power_2 = 0
      sum_power_3 = 0
      #custom overlaping windows
      for idx in range(27):
          max_pow = 0
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power(and sum all max powers for std pped)
          power_1 = np.sum(power.T[0:5])
          power_2 = np.sum(power.T[5:9])
          power_3 = np.sum(power.T[9:21])
          sum_power_1+=(power_1-mean_pped[counter_file][0])**2
          sum_power_2+=(power_2-mean_pped[counter_file][1])**2
          sum_power_3+=(power_3-mean_pped[counter_file][2])**2
      #append values in lists 
      std_dev_pped.append([sqrt(sum_power_1/26),sqrt(sum_power_2/26),sqrt(sum_power_3/26)])
      
         
      counter_file+=1

#COMPUTE CREST FACTOR(TASK 8)

crest_factor = []

counter_file = 0
for file in Unique_Labels_List:
      
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      
      #crest factor value to append
      mean_cf = 0
      for idx in range(27):
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power
          max_pow = np.amax(power)
          s_power = power**2
          sum_power = np.sum(s_power)
          mean_cf+=max_pow/(sqrt(sum_power/power.shape[0]))

         
      #append values in lists 
      crest_factor.append(mean_cf/27)
      counter_file+=1


#additional mean kurtosis and skewness for dominant power and frequency in window


kurt_pow = []
skew_pow = []
kurt_freq = []
skew_freq = []
counter_file = 0
for file in Unique_Labels_List:
      
      df = pd.read_csv(path_to_data + '/' + file)
      data = np.asarray(df)
      #scale between given values
      data = set_range(data,0,65535)
      #reshape in order to fit in StandardScaler
      data = scaling(data.reshape(-1,1))
      #downsample
      data = downsampling(data)
      low = 0.0065
      high = 0.25
      #get butterworth best fit output
      data = butter_bandpass_filter(data,low,high,1,4)
      #sums for stds
      sum_pow_skew = 0
      sum_pow_kurt = 0
      sum_freq_skew = 0
      sum_freq_kurt = 0
      #custom overlaping windows
      for idx in range(27):
          max_pow = 0
          #splititing in windows
          n_data = data[idx*120:480 + idx*120]
          #get spectrum with welch method: fs = 2Hz, noverlap = 0 since custom overlaping windows
          freq,power = welch(n_data.T,fs = 2.0, noverlap = 0)
          #get max power(and sum all max powers)
          max_pow= np.amax(power)
          #get idx of max power
          max_idx = (np.where(power == np.amax(power)))
          #create sum in order to compute standard deviation for power
          sum_pow_skew += ((max_pow - mean_dom_power_window[counter_file])/std_dev_pow[counter_file])**3
          sum_pow_kurt += ((max_pow - mean_dom_power_window[counter_file])/std_dev_pow[counter_file])**4
          #get max frequency(and sum all max frequencies)
          max_freq=freq[max_idx[1]]
          #create sum in order to compute standard deviation for power
          sum_freq_skew +=((max_freq - mean_dom_freq_window[counter_file])/std_dev_freq[counter_file])**3
          sum_freq_kurt +=((max_freq - mean_dom_freq_window[counter_file])/std_dev_freq[counter_file])**4
      #append values in lists 
      
      s_pow = sum_pow_skew/27
      k_pow = sum_pow_kurt/27
      s_freq = sum_freq_skew/27
      k_freq = sum_freq_kurt/27
      skew_pow.append(s_pow)
      skew_freq.append(s_freq)
      kurt_pow.append(k_pow)
      kurt_freq.append(k_freq)
         
      counter_file+=1

"""FINALIZE PROCESSING AND CREATE FETURES:
FEATURES:{crest_factor,std_dev_pped,mean_pped,PIC,FIC,DPR,std_dev_pow,std_dev_freq,normal_gastric_percentage,pped_dist,mean_dom_power_window,mean_dom_freq_window ,max_power_total, max_freq_total}

N_features  = 39 THEREFORE 39-D SPACE FOR CLASSIFICATION 
"""

ABSP = []
ABSF = []
ABKP = []
ABKF = []
for idx in range(int(len(kurt_pow)/2)):
  #computed from formula
  ABSP.append(skew_pow[2*idx]/skew_pow[2*idx+1])
  ABKP.append(kurt_pow[2*idx]/kurt_pow[2*idx+1])
  ABSF.append(skew_freq[2*idx]/skew_freq[2*idx+1])
  ABKF.append(kurt_freq[2*idx]/kurt_freq[2*idx+1])


crest_factor = np.asarray(crest_factor)
std_dev_pped = np.asarray(std_dev_pped)
mean_pped    = np.asarray(mean_pped)
PIC = np.asarray(PIC)
FIC = np.asarray(FIC)
DPR = np.asarray(DPR)
std_dev_pow = np.asarray(std_dev_pow,)
std_dev_freq =np.asarray(std_dev_freq)
normal_gastric_percentage = np.asarray(normal_gastric_percentage)
pped_dist = np.asarray(pped_dist)
mean_dom_power_window = np.asarray(mean_dom_power_window)
mean_dom_freq_window = np.asarray(mean_dom_freq_window)
max_power_total = np.asarray(max_power_total)
max_freq_total = np.asarray(max_freq_total)
kurt_pow = np.asarray(kurt_pow)
kurt_freq = np.asarray(kurt_freq)
skew_pow = np.asarray(skew_pow)
skew_freq = np.asarray(skew_freq)
ABKP = np.asarray(ABKP)
ABKF = np.asarray(ABKF)
ABSP = np.asarray(ABSP)
ABSF = np.asarray(ABSF)

#NEXT LINER ARE FOR MERGING FEATURES AND SUBJECTS

max_freq_total = max_freq_total.reshape(14,2)
max_power_total = max_power_total.reshape(14,2)
mean_dom_freq_window = mean_dom_freq_window.reshape(14,2)
mean_dom_power_window = mean_dom_power_window.reshape(14,2)
pped_dist = pped_dist.reshape(14,6)
normal_gastric_percentage = normal_gastric_percentage.reshape(14,2)
std_dev_freq = std_dev_freq.reshape(14,2)
std_dev_pow = std_dev_pow.reshape(14,2)
DPR = DPR.reshape(14,1)
PIC = PIC.reshape(14,2)
FIC = FIC.reshape(14,2)
mean_pped = mean_pped.reshape(14,6)
std_dev_pped = std_dev_pped.reshape(14,6)
crest_factor = crest_factor.reshape(14,2)
kurt_pow = kurt_pow.reshape(14,2)
kurt_freq = kurt_freq.reshape(14,2)
skew_pow = skew_pow.reshape(14,2)
skew_freq = skew_freq.reshape(14,2)
ABKP = ABKP.reshape(14,1)
ABKF = ABKF.reshape(14,1)
ABSP = ABSP.reshape(14,1)
ABSF = ABSF.reshape(14,1)

data_frame = np.concatenate((max_freq_total.T,max_power_total.T,mean_dom_freq_window.T,mean_dom_power_window.T,pped_dist.T,normal_gastric_percentage.T,std_dev_freq.T,std_dev_pow.T,DPR.T,PIC.T,FIC.T,mean_pped.T,std_dev_pped.T,crest_factor.T))
data_frame_advanced = np.concatenate((max_freq_total.T,max_power_total.T,mean_dom_freq_window.T,mean_dom_power_window.T,pped_dist.T,normal_gastric_percentage.T,std_dev_freq.T,std_dev_pow.T,DPR.T,PIC.T,FIC.T,mean_pped.T,std_dev_pped.T,crest_factor.T,kurt_pow.T,kurt_freq.T,skew_pow.T,skew_freq.T,ABKP.T,ABKF.T,ABSP.T,ABSF.T))
data_frame_advanced = data_frame_advanced.T

print(data_frame.shape)
data_frame = data_frame.T

cols = ["ODF after",'ODF before','ODP after','ODP before','DF after','DF before','DP after','DP before','PPED after zone 1','PEPD after zone 2'
        ,'PEPD after zone 3','PEPD before zone 1','PEPD before zone 2','PEPD before zone 3','NGSW before','NGSW after','STD DEV Frequencies after',
        'STD DEV Frequencies before','STD DEV Power after','STD DEV Power before','DPR','FIC after','FIC before','PIC after','PIC before',
        'Mean PEPD after zone 1','Mean PEPD after zone 2','Mean PEPD after zone 3','Mean PEPD before zone 1','Mean PEPD before zone 2','Mean PEPD before zone 3',
        'STD DEV PEPD after zone 1','STD DEV PEPD after zone 2','STD DEV PEPD after zone 3',
        'STD DEV PEPD before zone 1','STD DEV PEPD before zone 2','STD DEV PEPD before zone 3','CF after','CF before']


cols_advanced = ["ODF after",'ODF before','ODP after','ODP before','DF after','DF before','DP after','DP before','PPED after zone 1','PEPD after zone 2'
                ,'PEPD after zone 3','PEPD before zone 1','PEPD before zone 2','PEPD before zone 3','NGSW before','NGSW after','STD DEV Frequencies after',
                'STD DEV Frequencies before','STD DEV Power after','STD DEV Power before','DPR','FIC after','FIC before','PIC after','PIC before',
                'Mean PEPD after zone 1','Mean PEPD after zone 2','Mean PEPD after zone 3','Mean PEPD before zone 1','Mean PEPD before zone 2','Mean PEPD before zone 3',
                'STD DEV PEPD after zone 1','STD DEV PEPD after zone 2','STD DEV PEPD after zone 3',
                'STD DEV PEPD before zone 1','STD DEV PEPD before zone 2','STD DEV PEPD before zone 3','CF after','CF before','Mean Kurtosis Power after','Mean Kurtosis Power before',
                'Mean Kurtosis Freq after','Mean Kurtosis Freq before','Mean Skewness Power after','Mean Skewness Power before',
                'Mean Skewness Freq after','Mean Skewness Freq before','KPR','KFR','SPR','SFR']

df_total = pd.DataFrame(data_frame, columns = cols)
df_normal = pd.DataFrame(data_frame[[0,2,4,6,8,10,12]],columns=cols)
df_pd = pd.DataFrame(data_frame[[1,3,5,7,9,11,13]],columns = cols)

df_total_ = pd.DataFrame(data_frame_advanced, columns = cols_advanced)
df_normal_ = pd.DataFrame(data_frame_advanced[[0,2,4,6,8,10,12]],columns=cols_advanced)
df_pd_ = pd.DataFrame(data_frame_advanced[[1,3,5,7,9,11,13]],columns = cols_advanced)

if not os.path.exists('./dataframes'):
  os.mkdir('./dataframes')
df_normal.to_csv('./dataframes/'+'Healthy.csv',header=True,index=True)
df_pd.to_csv('./dataframes/'+'Parcinson.csv',header = True,index = True)
df_total.to_csv('./dataframes/'+'Total.csv',header = True,index = True)

if not os.path.exists('./dataframes_expanded'):
  os.mkdir('./dataframes_expanded')
df_normal_.to_csv('./dataframes_expanded/'+'Healthy.csv',header=True,index=True)
df_pd_.to_csv('./dataframes_expanded/'+'Parcinson.csv',header = True,index = True)
df_total_.to_csv('./dataframes_expanded/'+'Total.csv',header = True,index = True)


if not os.path.exists('./histograms'):
   os.mkdir('./histograms')
if not os.path.exists('./boxplots'):
   os.mkdir('./boxplots')

"""HISTOGRAMMS AND BOXPLOTS"""

for idx in range(df_pd.shape[1]):
  df_pd.hist(column = cols[idx]) 
  plt.savefig('./histograms/'+'Parcinson '+ cols[idx] + '.png')

for idx in range(df_pd.shape[1]):
  df_normal.hist(column = cols[idx]) 
  plt.savefig('./histograms/'+'Healthy '+ cols[idx] + '.png')

for idx in range(df_pd.shape[1]):
  df_total.hist(column = cols[idx]) 
  plt.savefig('./histograms/'+'Total '+ cols[idx] + '.png')

n_pd = df_pd.to_numpy()
for idx in range(df_pd.shape[1]):
  plt.boxplot(n_pd.T[idx])
  plt.title("Parcinson " + cols[idx])
  plt.ylabel(cols[idx])
  plt.savefig('./boxplots/'+'Parcinson '+ cols[idx] + '.png')
  plt.show()

n_normal = df_normal.to_numpy()
for idx in range(df_normal.shape[1]):
  plt.boxplot(n_normal.T[idx])
  plt.title("Healthy " + cols[idx])
  plt.ylabel(cols[idx])
  plt.savefig('./boxplots/'+'Healthy '+ cols[idx] + '.png')
  plt.show()

n_total = df_total.to_numpy()
for idx in range(df_total.shape[1]):
  plt.boxplot(n_total.T[idx])
  plt.title("Total " + cols[idx])
  plt.ylabel(cols[idx])
  plt.savefig('./boxplots/'+'Total '+ cols[idx] + '.png')
  plt.show()

#Hypothesis Testing
mannwhitney = []
ranksum = []
alpha = 0.01

for idx in range(df_normal_.shape[1]):
  mannwhitney.append(mannwhitneyu(df_normal_[cols_advanced[idx]], df_pd_[cols_advanced[idx]]))
  ranksum.append(ranksums(df_normal_[cols_advanced[idx]], df_pd_[cols_advanced[idx]]))
print(np.asarray(ranksum))
print(np.asarray(mannwhitney))
rank_sum_idx = []
mannwhtn_idx = []

#check which feature returns true for statistical significance p-val = 1%
#this means, which feature(s) of our dataset have significantly different distribution in our dataset between PD and Healthy(DPR)

for idx in range(np.asarray(ranksum).shape[0]):
  if np.asarray(ranksum)[idx,1]<alpha:
    rank_sum_idx.append(idx)
  if np.asarray(mannwhitney)[idx,1]<alpha:
    mannwhtn_idx.append(idx)
print(rank_sum_idx)
print(mannwhtn_idx)
print(df_total_.columns.values[mannwhtn_idx])

